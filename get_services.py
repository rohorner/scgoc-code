#!/usr/bin/env python

from datetime import datetime
from dateutil.relativedelta import relativedelta
from pytz import timezone
from pprint import pprint
from crontab import CronTab
import requests
import json

SERVICES_URL = 'http://stcatherinechurch.org/services'
CRONFILE = './crontab.tab'
START_COMMAND = '/home/stcatherine/streaming'
STOP_COMMAND = '/home/stcatherine/ending'

class StreamableEvent():
    def __init__(self, id, title, start, end):
        self.id = id        # ID of the event. We use the one generated by Squarespace to keep things consistent
        self.title = title
        self.start_time = start
        self.end_time = end
        self.cronStart = '' # The command we'll insert in crontab to start the stream or recording
        self.cronStop = ''   # The command we'll insert in crontab to stop the stream or recording

    def __repr__(self):
        return 'StreamableEvent(\n\t%s\n\t%s\n\t(%s:%s)\n)' % (
            self.id, self.title,
            self.start_time, self.end_time)

#Get the 'MONTH-YEAR' string that we'll insert into the requests call to get a specific month of events
def get_month_string(offset):
    return (datetime.today() + relativedelta(months=+offset)).strftime('%B-%Y')

# Grab the JSON representation of the page
def get_page_json(url, offset):
    month_string = get_month_string(offset)
    # Squarespace returns a JSON object with lots of goodies if you append '?format=json' to the page path
    r = requests.get(url+'?month='+month_string+'&format=json')
    # return the content as a json dict object
    if r.status_code == 200:
        return [r.url, json.loads(r.content)]
    elif r.status_code == 429:
        print "Squarespace asked us to slow down on the requests. Wait a few minutes."
    else:
        print 'get_page_json(url="%s", offset="%s") returned status code %s' % (r.url, offset, r.status_code)

# Make sure the event time representation is in Denver timezone
def return_mountain_time(timestamp):
    return datetime.fromtimestamp(timestamp/1000, tz=timezone('US/Mountain')).strftime('%A %b %d %X')

if __name__ == '__main__':

    # Create or load the cron file (just a test file for now)
    try:
        #crontab = CronTab(tabfile=CRONFILE)
        crontab = CronTab(user='stcatherine')
    except:
        print ("Couldn't load cron file:", CRONFILE)

    # Get events for this month (offset 0) and next month (offset +1)
    # to make sure we have a good list of streaming events
    for offset in [0,1]:
        # get_page_json returns a list: the crafted URL as a string and the response as a json object
        called_url, response = get_page_json(SERVICES_URL, offset)
        # print 'called get_page_json with URL: %s' % called_url
        # Find events with a "Services" category. We'll set up streaming for all of these.
        # Build a list of all _future_ RecordableEvent objects
        try:
            for event in response['items']:
                if 'Stream' in event['categories']:
                    this_event = StreamableEvent(event['id'],
                                                 event['title'],
                                                 event['startDate'],
                                                 event['endDate']
                                                 )
                    job = crontab.new(command=START_COMMAND, comment = this_event.id+'::'+this_event.title)
                    job.setall(datetime.fromtimestamp(this_event.start_time/1000))

                    job = crontab.new(command=STOP_COMMAND, comment = this_event.id)
                    job.setall(datetime.fromtimestamp(this_event.end_time/1000))

                    # Commit the job to the cron
                    crontab.write()
                    # print this_event
        except KeyError, e:
            print '\nWARNING: No Services found response for %s\n' % called_url

    print "I'll build this crontab:"
    for job in crontab:
        print job

